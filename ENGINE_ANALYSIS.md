# KoSPA ë¶„ì„ ì—”ì§„ ìƒì„¸ ë¶„ì„ ë° ë¬¸ì œì  ì§„ë‹¨

**ë¶„ì„ ì¼ì**: 2025-11-02
**ë¶„ì„ ëŒ€ìƒ**: `vowel_v2.py`, `consonant.py`
**ëª©ì **: ë¡œì§ ê²€ì¦, ì ì¬ì  ë²„ê·¸ ë°œê²¬, ì½”ë“œ íë¦„ íŒŒì•…

---

## ëª©ì°¨

1. [ì—”ì§„ ê°„ ì˜ì¡´ì„± ë§µ](#1-ì—”ì§„-ê°„-ì˜ì¡´ì„±-ë§µ)
2. [Vowel Engine ìƒì„¸ ë¶„ì„](#2-vowel-engine-ìƒì„¸-ë¶„ì„)
3. [Consonant Engine ìƒì„¸ ë¶„ì„](#3-consonant-engine-ìƒì„¸-ë¶„ì„)
4. [ë°œê²¬ëœ ë¬¸ì œì  ë° ê¶Œì¥ ì‚¬í•­](#4-ë°œê²¬ëœ-ë¬¸ì œì -ë°-ê¶Œì¥-ì‚¬í•­)
5. [ì½”ë“œ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨](#5-ì½”ë“œ-í”Œë¡œìš°-ë‹¤ì´ì–´ê·¸ë¨)

---

## 1. ì—”ì§„ ê°„ ì˜ì¡´ì„± ë§µ

### 1.1 ì „ì²´ ì‹œìŠ¤í…œ ì—°ê²° êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        main.py (FastAPI)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                            â”‚
         â–¼                                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   vowel_v2.py        â”‚                  â”‚   consonant.py       â”‚
â”‚                      â”‚                  â”‚                      â”‚
â”‚ analyze_single_audio â”‚â—€â”€â”€â”€â”€â”            â”‚ analyze_one_file     â”‚
â”‚         â”‚            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â–¼            â”‚
â”‚ convert_to_wav       â”‚â—€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ convert_to_wav       â”‚
â”‚         â”‚            â”‚     â”‚            â”‚   (from vowel_v2)    â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚ analyze_vowel_and_   â”‚     â”‚            â”‚         â–¼            â”‚
â”‚   pitch              â”‚     â”‚            â”‚ load_sound           â”‚
â”‚         â”‚            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â–¼            â”‚
â”‚ _stable_window       â”‚     â”‚            â”‚ extract_features_    â”‚
â”‚         â”‚            â”‚     â”‚            â”‚   for_syllable       â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚ parselmouth.Sound    â”‚     â”‚            â”‚         â”œâ”€â–¶ VOT      â”‚
â”‚   .to_pitch()        â”‚     â”‚            â”‚         â”œâ”€â–¶ Fricationâ”‚
â”‚   .to_formant_burg() â”‚     â”‚            â”‚         â””â”€â–¶ Nasal    â”‚
â”‚         â”‚            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â–¼            â”‚
â”‚ compute_score        â”‚     â”‚            â”‚ score_against_       â”‚
â”‚         â”‚            â”‚     â”‚            â”‚   reference          â”‚
â”‚         â–¼            â”‚     â”‚            â”‚         â”‚            â”‚
â”‚ get_feedback         â”‚     â”‚            â”‚         â–¼            â”‚
â”‚         â”‚            â”‚     â”‚            â”‚ (advice_list)        â”‚
â”‚         â–¼            â”‚     â”‚            â”‚                      â”‚
â”‚ (optional)           â”‚     â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ plot_single_vowel_   â”‚     â”‚
â”‚   space              â”‚     â”‚
â”‚         â”‚            â”‚     â”‚
â”‚         â–¼            â”‚     â”‚
â”‚ matplotlib.pyplot    â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
                             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Shared Dependency
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  System Tools        â”‚
â”‚                      â”‚
â”‚ â€¢ FFmpeg (subprocess)â”‚
â”‚ â€¢ Parselmouth (Praat)â”‚
â”‚ â€¢ NumPy              â”‚
â”‚ â€¢ SciPy              â”‚
â”‚ â€¢ Matplotlib         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 main.pyì™€ ì—”ì§„ ì—°ê²°

#### main.py â†’ vowel_v2.py
```python
# main.py:15-22
from analysis.vowel_v2 import (
    analyze_single_audio,       # í•µì‹¬ ë¶„ì„ í•¨ìˆ˜
    convert_to_wav,             # ì˜¤ë””ì˜¤ ë³€í™˜
    STANDARD_MALE_FORMANTS,     # ì°¸ì¡° ë°ì´í„°
    STANDARD_FEMALE_FORMANTS,   # ì°¸ì¡° ë°ì´í„°
    plot_single_vowel_space,    # ì‹œê°í™”
)

# main.py:124-166 (run_vowel_analysis í•¨ìˆ˜)
def run_vowel_analysis(audio_path: str, symbol: str):
    vowel_key = VOWEL_SYMBOL_TO_KEY[symbol]  # "ã…" â†’ "a (ì•„)"
    result, error = analyze_single_audio(audio_path, vowel_key, return_reason=True)

    if error:
        raise ValueError(error)

    # í¬ë¨¼íŠ¸ í”Œë¡¯ ìƒì„±
    plot_single_vowel_space(f1, f2, vowel_key, gender, plot_path)

    return {...}  # JSON ì‘ë‹µ
```

#### main.py â†’ consonant.py
```python
# main.py:15
from analysis import consonant as consonant_analysis

# main.py:169-228 (run_consonant_analysis í•¨ìˆ˜)
def run_consonant_analysis(audio_path: str, symbol: str):
    syllable = CONSONANT_SYMBOL_TO_SYLLABLE[symbol]  # "ã„±" â†’ "ê°€"
    info = consonant_analysis.reference.get(syllable)

    # ì˜¤ë””ì˜¤ ë³€í™˜ (vowel_v2ì˜ í•¨ìˆ˜ ì¬ì‚¬ìš©)
    from analysis.vowel_v2 import convert_to_wav
    convert_to_wav(audio_path, wav_path)

    # ììŒ ë¶„ì„
    snd, y, sr = consonant_analysis.load_sound(wav_path)
    measured = consonant_analysis.extract_features_for_syllable(...)
    f0, sex = consonant_analysis.estimate_speaker_f0_and_sex(...)
    score, advice = consonant_analysis.score_against_reference(...)

    return {...}
```

**ì¤‘ìš”**: consonant.pyëŠ” `convert_to_wav`ë¥¼ vowel_v2.pyì—ì„œ importí•˜ì—¬ ì‚¬ìš©í•©ë‹ˆë‹¤ (ì½”ë“œ ì¬ì‚¬ìš©).

---

## 2. Vowel Engine ìƒì„¸ ë¶„ì„

### 2.1 í•µì‹¬ í•¨ìˆ˜ í”Œë¡œìš°

```
analyze_single_audio(audio_path, vowel_key)
    â”‚
    â”œâ”€â–¶ 1. íŒŒì¼ ì¡´ì¬ í™•ì¸ (vowel_v2.py:232-236)
    â”‚
    â”œâ”€â–¶ 2. FFmpeg ë³€í™˜ (vowel_v2.py:243-249)
    â”‚       convert_to_wav(input, "kospa_temp.wav")
    â”‚           â”‚
    â”‚           â””â”€â–¶ subprocess.run(["ffmpeg", "-i", input,
    â”‚                   "-y", "-ac", "1", "-ar", "44100", output])
    â”‚
    â”œâ”€â–¶ 3. í¬ë¨¼íŠ¸ ë° í”¼ì¹˜ ì¶”ì¶œ (vowel_v2.py:257)
    â”‚       analyze_vowel_and_pitch("kospa_temp.wav")
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ì˜¤ë””ì˜¤ ë¡œë“œ (vowel_v2.py:120)
    â”‚           â”‚       snd_full = parselmouth.Sound(wav_path)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ Stable Window ì¶”ì¶œ (vowel_v2.py:126)
    â”‚           â”‚       _stable_window(snd_full, min_len=0.12)
    â”‚           â”‚           â”‚
    â”‚           â”‚           â”œâ”€â–¶ RMS ê³„ì‚° (hop=win_size//4)
    â”‚           â”‚           â”‚       for ê° ìœˆë„ìš°:
    â”‚           â”‚           â”‚           rms = sqrt(mean(segment^2))
    â”‚           â”‚           â”‚
    â”‚           â”‚           â”œâ”€â–¶ ìµœê³  ì—ë„ˆì§€ ìœˆë„ìš° ì„ íƒ
    â”‚           â”‚           â”‚       rms_list.sort(reverse=True)
    â”‚           â”‚           â”‚       best_rms, best_idx = rms_list[0]
    â”‚           â”‚           â”‚
    â”‚           â”‚           â”œâ”€â–¶ SNR ê³„ì‚°
    â”‚           â”‚           â”‚       noise_floor = median(all_rms)
    â”‚           â”‚           â”‚       snr_ratio = best_rms / noise_floor
    â”‚           â”‚           â”‚
    â”‚           â”‚           â””â”€â–¶ ì„œë¸Œ ì˜¤ë””ì˜¤ ì¶”ì¶œ
    â”‚           â”‚                   sound.extract_part(start_t, end_t)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ í’ˆì§ˆ ê²€ì‚¬ (vowel_v2.py:130-137)
    â”‚           â”‚       if seg_len < 0.08: "Too short"
    â”‚           â”‚       if peak_rms < 0.01: "Volume too low"
    â”‚           â”‚       if snr_ratio < 1.5: "Background noise high"
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ í”¼ì¹˜ ì¶”ì¶œ (vowel_v2.py:139-143)
    â”‚           â”‚       pitch = stable.to_pitch(
    â”‚           â”‚           pitch_floor=75.0,
    â”‚           â”‚           pitch_ceiling=500.0
    â”‚           â”‚       )
    â”‚           â”‚       voiced = [f for f in pitch_values if f > 0]
    â”‚           â”‚       f0_mean = mean(voiced)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ í¬ë¨¼íŠ¸ ì¶”ì¶œ (vowel_v2.py:145-156)
    â”‚           â”‚       formant = stable.to_formant_burg(
    â”‚           â”‚           maximum_formant=5500.0
    â”‚           â”‚       )
    â”‚           â”‚       for each frame:
    â”‚           â”‚           f1_vals.append(formant.get_value_at_time(1, t))
    â”‚           â”‚           f2_vals.append(formant.get_value_at_time(2, t))
    â”‚           â”‚           f3_vals.append(formant.get_value_at_time(3, t))
    â”‚           â”‚
    â”‚           â”‚       f1_mean = nanmedian(f1_vals)
    â”‚           â”‚       f2_mean = nanmedian(f2_vals)
    â”‚           â”‚       f3_mean = nanmedian(f3_vals)
    â”‚           â”‚
    â”‚           â””â”€â–¶ ë°˜í™˜ (vowel_v2.py:162)
    â”‚                   return f1, f2, f3, f0, quality_hint
    â”‚
    â”œâ”€â–¶ 4. ì„±ë³„ íŒë³„ (vowel_v2.py:271-272)
    â”‚       gender = "Male" if f0 < 165.0 else "Female"
    â”‚       ref_table = MALE_FORMANTS or FEMALE_FORMANTS
    â”‚
    â”œâ”€â–¶ 5. ì ìˆ˜ ê³„ì‚° (vowel_v2.py:281)
    â”‚       compute_score(f1, f2, f3, vowel_key, ref_table)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ Z-score ê³„ì‚° (vowel_v2.py:173-174)
    â”‚           â”‚       f1_z = abs(f1 - ref_f1) / ref_f1_sd
    â”‚           â”‚       f2_z = abs(f2 - ref_f2) / ref_f2_sd
    â”‚           â”‚       z_avg = (f1_z + f2_z) / 2
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ F3 ê°€ì¤‘ì¹˜ ì ìš© (vowel_v2.py:178-181)
    â”‚           â”‚       if f3 exists:
    â”‚           â”‚           f3_z = abs(f3 - ref_f3) / f3_sd
    â”‚           â”‚           z_avg = z_avg * 0.75 + f3_z * 0.25
    â”‚           â”‚
    â”‚           â””â”€â–¶ ì ìˆ˜ ë³€í™˜ (vowel_v2.py:183-188)
    â”‚                   if z_avg <= 1.5: score = 100
    â”‚                   else: score = 100 - (z_avg - 1.5) * 60
    â”‚
    â”œâ”€â–¶ 6. í”¼ë“œë°± ìƒì„± (vowel_v2.py:282)
    â”‚       get_feedback(vowel_key, f1, f2, ref_table, quality_hint)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ F1 ë¹„êµ (vowel_v2.py:202-205)
    â”‚           â”‚       if f1 > ref_f1 + tol:
    â”‚           â”‚           "Mouth too open / tongue too low"
    â”‚           â”‚       elif f1 < ref_f1 - tol:
    â”‚           â”‚           "Mouth too closed / tongue too high"
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ F2 ë¹„êµ (vowel_v2.py:207-211)
    â”‚           â”‚       if f2 > ref_f2 + tol:
    â”‚           â”‚           "Tongue too front"
    â”‚           â”‚       elif f2 < ref_f2 - tol:
    â”‚           â”‚           "Tongue too back"
    â”‚           â”‚
    â”‚           â””â”€â–¶ í’ˆì§ˆ íŒíŠ¸ ì¶”ê°€ (vowel_v2.py:216-217)
    â”‚                   if quality_hint: append to feedback
    â”‚
    â””â”€â–¶ 7. ê²°ê³¼ ë°˜í™˜ (vowel_v2.py:284-298)
            return {
                "vowel_key", "gender", "f0", "f1", "f2", "f3",
                "score", "feedback", "quality_hint"
            }, None
```

### 2.2 ë°œê²¬ëœ ì ì¬ì  ë¬¸ì œì 

#### ğŸ”´ **P1: ì„ì‹œ íŒŒì¼ ê³ ì •ëª… (Race Condition ìœ„í—˜)**

**ìœ„ì¹˜**: `vowel_v2.py:243`

```python
tmp_wav = "kospa_temp.wav"  # âŒ ê³ ì •ëœ íŒŒì¼ëª…
```

**ë¬¸ì œ**:
- ë™ì‹œì— ì—¬ëŸ¬ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ê°™ì€ íŒŒì¼ì„ ë®ì–´ì“°ê²Œ ë¨
- ë©€í‹°ìŠ¤ë ˆë“œ/ë©€í‹°í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œ ì¶©ëŒ ê°€ëŠ¥

**ì˜ˆìƒ ì‹œë‚˜ë¦¬ì˜¤**:
```
Time    Thread A                Thread B
0ms     convert_to_wav("a.m4a", "kospa_temp.wav")
10ms                            convert_to_wav("b.m4a", "kospa_temp.wav")  # âŒ ë®ì–´ì”€!
50ms    analyze("kospa_temp.wav")  # âŒ b.m4a ë‚´ìš© ë¶„ì„!
```

**í•´ê²°ì±…**:
```python
import tempfile
import uuid

# ì˜µì…˜ 1: tempfile ì‚¬ìš©
with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
    tmp_wav = tmp.name

# ì˜µì…˜ 2: UUID ì‚¬ìš©
tmp_wav = f"kospa_temp_{uuid.uuid4().hex}.wav"
```

**ì˜í–¥ë„**: ğŸ”¥ ë†’ìŒ (í”„ë¡œë•ì…˜ì—ì„œ ê°„í—ì  ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥)

---

#### ğŸŸ¡ **P2: ì„±ë³„ íŒë³„ ì„ê³„ê°’ ë‹¨ìˆœí™”**

**ìœ„ì¹˜**: `vowel_v2.py:43, 271`

```python
F0_GENDER_THRESHOLD = 165.0  # ê³ ì •ê°’

gender_guess = "Male" if f0 < F0_GENDER_THRESHOLD else "Female"
```

**ë¬¸ì œ**:
- 165Hz ê·¼ì²˜ì—ì„œ ë¶ˆì•ˆì • (ì˜ˆ: 164Hz â†” 166Hz ì°¨ì´ê°€ ê·¹ëª…)
- ê°œì¸ì°¨ ê³ ë ¤ ì•ˆ ë¨ (ë†’ì€ ìŒì—­ëŒ€ ë‚¨ì„±, ë‚®ì€ ìŒì—­ëŒ€ ì—¬ì„±)
- ê²€ì¦ ê²°ê³¼: `sample/vowel_man/` ìƒ˜í”Œì´ ì—¬ì„±ìœ¼ë¡œ íŒë³„ë¨ (F0 169~241Hz)

**ê°œì„  ë°©ì•ˆ**:
```python
# ì˜µì…˜ 1: Soft threshold with confidence
def guess_gender_with_confidence(f0):
    if f0 < 140:
        return "Male", 0.95
    elif f0 < 160:
        return "Male", 0.70
    elif f0 < 180:
        return "Female", 0.70  # Ambiguous zone
    else:
        return "Female", 0.95

# ì˜µì…˜ 2: Use calibration data
if user_calibration_exists:
    gender = user_calibration["gender"]
else:
    gender = guess_from_f0(f0)
```

**ì˜í–¥ë„**: ğŸŸ¡ ì¤‘ê°„ (ì •í™•ë„ ì €í•˜, but ì¹˜ëª…ì ì´ì§„ ì•ŠìŒ)

---

#### ğŸŸ¡ **P3: ì ìˆ˜ ê³„ì‚° ë¶ˆì¼ì¹˜**

**ìœ„ì¹˜**: `vowel_v2.py:183` vs `consonant.py:797`

**Vowel Engine**:
```python
if z_avg <= 1.5:  # 1.5Ïƒ ì´ë‚´
    return 100
penalty = (z_avg - 1.5) * 60.0  # 60ì /Ïƒ
```

**Consonant Engine**:
```python
if avg_abs_z <= 1.5:  # ë™ì¼
    overall_score = 100
penalty = (avg_abs_z - 1.5) * 60.0  # ë™ì¼
```

**ë¬¸ì œ**: README.mdì—ëŠ” "Â±2.5Ïƒ ê¸°ì¤€"ì´ë¼ê³  ëª…ì‹œë˜ì–´ ìˆì§€ë§Œ, ì‹¤ì œ ì½”ë“œëŠ” 1.5Ïƒ ì‚¬ìš©.

**ì¶œì²˜**: `README.md:66-68`
```markdown
- **Vowels** â€“ F1/F2/F3 deviations are converted to Ïƒ units. Average z â‰¤ 2.5
  scores 100; beyond that, the score decreases linearly (â‰ˆ40 points per Ïƒ).
```

**ë¬¸ì„œì™€ ì½”ë“œ ë¶ˆì¼ì¹˜**:
- ë¬¸ì„œ: 2.5Ïƒ, 40ì /Ïƒ
- ì‹¤ì œ: 1.5Ïƒ, 60ì /Ïƒ

**ê¶Œì¥**:
1. ì½”ë“œë¥¼ ë¬¸ì„œì— ë§ì¶”ê±°ë‚˜
2. ë¬¸ì„œë¥¼ ì½”ë“œì— ë§ì¶° ìˆ˜ì •

**ì˜í–¥ë„**: ğŸŸ¡ ì¤‘ê°„ (ê¸°ëŠ¥ ì‘ë™í•˜ì§€ë§Œ í˜¼ë€ ì´ˆë˜)

---

#### ğŸŸ¢ **P4: F3 ê°€ì¤‘ì¹˜ ë¡œì§ ë¶ˆëª…í™•**

**ìœ„ì¹˜**: `vowel_v2.py:178-181`

```python
if "f3" in std and f3:
    f3_sd = std.get("f3_sd", 250.0)  # âŒ f3_sdê°€ ì—†ìœ¼ë©´ 250Hz ì‚¬ìš©
    f3_z = abs(f3 - std["f3"]) / f3_sd
    z_avg = (z_avg * 0.75) + (f3_z * 0.25)
```

**ë¬¸ì œ**:
- ì°¸ì¡° ë°ì´í„°ì— `f3_sd`ê°€ ì—†ìŒ (STANDARD_MALE_FORMANTS, STANDARD_FEMALE_FORMANTS)
- í•­ìƒ 250Hzë¥¼ í‘œì¤€í¸ì°¨ë¡œ ì‚¬ìš©í•˜ê²Œ ë¨
- F3ì˜ ì‹¤ì œ ë³€ë™ì„±ì„ ë°˜ì˜í•˜ì§€ ëª»í•¨

**ë°ì´í„° í™•ì¸**:
```python
# vowel_v2.py:24-40
STANDARD_MALE_FORMANTS = {
    'a (ì•„)': {'f1': 651, 'f2': 1156, 'f3': 2500,
               'f1_sd': 136, 'f2_sd': 77},  # f3_sd ì—†ìŒ!
    ...
}
```

**í•´ê²°ì±…**:
```python
# ì˜µì…˜ 1: f3_sdë¥¼ ì°¸ì¡° ë°ì´í„°ì— ì¶”ê°€
STANDARD_MALE_FORMANTS = {
    'a (ì•„)': {..., 'f3_sd': 200},  # ì‹¤ì œ ì—°êµ¬ ë°ì´í„° ê¸°ë°˜
}

# ì˜µì…˜ 2: F3ë¥¼ ì ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸ (í˜„ì¬ë„ ì‚¬ì‹¤ìƒ ì˜ë¯¸ ì—†ìŒ)
z_avg = (f1_z + f2_z) / 2  # F3 ì œê±°
```

**ì˜í–¥ë„**: ğŸŸ¢ ë‚®ìŒ (F3ëŠ” 25% ê°€ì¤‘ì¹˜ë¡œ ì´ë¯¸ ë‚®ìŒ)

---

#### ğŸŸ¢ **P5: í’ˆì§ˆ íŒíŠ¸ ì„ê³„ê°’ í•˜ë“œì½”ë”©**

**ìœ„ì¹˜**: `vowel_v2.py:132-137`

```python
if seg_len < 0.08:  # âŒ ë§¤ì§ ë„˜ë²„
    quality_msgs.append("Too short; hold ~0.3s.")
if peak_rms < 0.01:  # âŒ ë§¤ì§ ë„˜ë²„
    quality_msgs.append("Volume too low; speak louder.")
if snr_ratio < 1.5:  # âŒ ë§¤ì§ ë„˜ë²„
    quality_msgs.append("Background noise high...")
```

**ê¶Œì¥**:
```python
# ìƒìˆ˜ë¡œ ì¶”ì¶œ
MIN_SEGMENT_LENGTH = 0.08
MIN_RMS_THRESHOLD = 0.01
MIN_SNR_RATIO = 1.5
```

**ì˜í–¥ë„**: ğŸŸ¢ ë‚®ìŒ (ê°€ë…ì„± ë¬¸ì œ, ê¸°ëŠ¥ì  ì˜í–¥ ì—†ìŒ)

---

### 2.3 ì„±ëŠ¥ ë¶„ì„

#### Stable Window ì¶”ì¶œ ë³µì¡ë„

**ìœ„ì¹˜**: `vowel_v2.py:86-91`

```python
hop = max(win_size // 4, 1)  # 25% overlap
for start_idx in range(0, len(snd_values) - win_size + 1, hop):
    seg = snd_values[start_idx:start_idx+win_size]
    rms = float(np.sqrt(np.mean(seg**2)))
    rms_list.append((rms, start_idx))
```

**ì‹œê°„ ë³µì¡ë„**: O(n * win_size)
- n = ì˜¤ë””ì˜¤ ê¸¸ì´ / hop
- 2ì´ˆ ì˜¤ë””ì˜¤ (44.1kHz): ~88,200 ìƒ˜í”Œ
- win_size = 0.12s * 44,100 = 5,292 ìƒ˜í”Œ
- hop = 5,292 / 4 â‰ˆ 1,323 ìƒ˜í”Œ
- ë°˜ë³µ íšŸìˆ˜: 88,200 / 1,323 â‰ˆ 67íšŒ
- ì´ ì—°ì‚°: 67 * 5,292 â‰ˆ 354,564 ì—°ì‚°

**ì²˜ë¦¬ ì‹œê°„**: ~10-50ms (NumPy ìµœì í™” ë•ë¶„)

**ìµœì í™” ê°€ëŠ¥ì„±**:
- ë‚®ìŒ (ì´ë¯¸ NumPyë¡œ ìµœì í™”ë¨)
- hop í¬ê¸°ë¥¼ ëŠ˜ë¦¬ë©´ ì •í™•ë„ ì €í•˜

---

## 3. Consonant Engine ìƒì„¸ ë¶„ì„

### 3.1 í•µì‹¬ í•¨ìˆ˜ í”Œë¡œìš°

```
analyze_one_file(wav_path, syllable)  # main í•¨ìˆ˜
    â”‚
    â”œâ”€â–¶ 1. ì°¸ì¡° ë°ì´í„° ë¡œë“œ (consonant.py:862)
    â”‚       info = reference.get(syllable)
    â”‚       ctype = info["type"]  # stop/fricative/affricate/sonorant
    â”‚
    â”œâ”€â–¶ 2. ì˜¤ë””ì˜¤ ë¡œë“œ (consonant.py:872-874)
    â”‚       load_sound(wav_path)
    â”‚           â”‚
    â”‚           â””â”€â–¶ snd = parselmouth.Sound(wav_path)
    â”‚               y = snd.values[0]  # mono signal
    â”‚               sr = snd.sampling_frequency
    â”‚
    â”œâ”€â–¶ 3. íŠ¹ì§• ì¶”ì¶œ (consonant.py:878)
    â”‚       extract_features_for_syllable(snd, y, sr, syllable, info)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ììŒ íƒ€ì…ë³„ ë¶„ê¸° (consonant.py:811-850)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ [STOP: ã„±, ã„·, ã…‚, ã…‹, ã…Œ, ã…, ã„², ã„¸, ã…ƒ]
    â”‚           â”‚       â”‚
    â”‚           â”‚       â”œâ”€â–¶ VOT ì¸¡ì • (consonant.py:817)
    â”‚           â”‚       â”‚       estimate_vot_ms(snd, aspirated_mode)
    â”‚           â”‚       â”‚           â”‚
    â”‚           â”‚       â”‚           â”œâ”€â–¶ Burst ê²€ì¶œ (consonant.py:360-383)
    â”‚           â”‚       â”‚           â”‚       detect_burst_time(snd)
    â”‚           â”‚       â”‚           â”‚           â”‚
    â”‚           â”‚       â”‚           â”‚           â”œâ”€â–¶ Intensity í”¼í¬ ì°¾ê¸°
    â”‚           â”‚       â”‚           â”‚           â”‚       intensity = snd.to_intensity()
    â”‚           â”‚       â”‚           â”‚           â”‚       max_intensity_frame
    â”‚           â”‚       â”‚           â”‚           â”‚
    â”‚           â”‚       â”‚           â”‚           â””â”€â–¶ burst_time ë°˜í™˜
    â”‚           â”‚       â”‚           â”‚
    â”‚           â”‚       â”‚           â”œâ”€â–¶ Voice Onset ê²€ì¶œ (consonant.py:385-428)
    â”‚           â”‚       â”‚           â”‚       aspirated_mode ë¶„ê¸°:
    â”‚           â”‚       â”‚           â”‚           if aspirated (ã…‹, ã…Œ, ã…, ã…Š):
    â”‚           â”‚       â”‚           â”‚               intensity_threshold = peak - 20dB
    â”‚           â”‚       â”‚           â”‚           else:
    â”‚           â”‚       â”‚           â”‚               intensity_threshold = peak - 30dB
    â”‚           â”‚       â”‚           â”‚
    â”‚           â”‚       â”‚           â”‚       find_voiced_onset_time()
    â”‚           â”‚       â”‚           â”‚
    â”‚           â”‚       â”‚           â””â”€â–¶ VOT = onset - burst (ms)
    â”‚           â”‚       â”‚
    â”‚           â”‚       â””â”€â–¶ Aspiration Ratio (consonant.py:819)
    â”‚           â”‚               aspiration_ratio_after_burst(y, sr, burst_t, voiced_t)
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ VOT êµ¬ê°„ ì‹ í˜¸ ì¶”ì¶œ
    â”‚           â”‚                   â”‚       vot_sig = y[burst_idx:onset_idx]
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ ê³ ì£¼íŒŒ ëŒ€ì—­ í•„í„°ë§
    â”‚           â”‚                   â”‚       bp_sig = bandpass(vot_sig, sr, 2000, 8000)
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ ì—ë„ˆì§€ ê³„ì‚°
    â”‚           â”‚                   â”‚       vot_energy = sum(bp_sig^2)
    â”‚           â”‚                   â”‚       vowel_energy = sum(vowel_sig^2)
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â””â”€â–¶ ratio = vot_energy / total_energy
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ [FRICATIVE: ã……, ã…†, ã…]
    â”‚           â”‚       â”‚
    â”‚           â”‚       â””â”€â–¶ Frication Stats (consonant.py:836)
    â”‚           â”‚               frication_stats(snd, y, sr)
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ Voice Onset ì°¾ê¸° (consonant.py:600-641)
    â”‚           â”‚                   â”‚       pitch ê¸°ë°˜ + intensity ê¸°ë°˜ ì¡°í•©
    â”‚           â”‚                   â”‚       first_voiced_time
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ Frication êµ¬ê°„ ì •ì˜
    â”‚           â”‚                   â”‚       fric_start = snd.xmin (ì‹œì‘)
    â”‚           â”‚                   â”‚       fric_end = first_voiced_time
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ ê³ ì£¼íŒŒ í•„í„°ë§ (consonant.py:655-656)
    â”‚           â”‚                   â”‚       fric_sig = bandpass(sig, sr, 2000, 12000)
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â”œâ”€â–¶ Spectral Centroid ê³„ì‚° (consonant.py:669)
    â”‚           â”‚                   â”‚       compute_spectral_centroid(fric_sig, sr)
    â”‚           â”‚                   â”‚           â”‚
    â”‚           â”‚                   â”‚           â”œâ”€â–¶ FFT ìˆ˜í–‰
    â”‚           â”‚                   â”‚           â”‚       spectrum = fft(signal)
    â”‚           â”‚                   â”‚           â”‚
    â”‚           â”‚                   â”‚           â”œâ”€â–¶ ê°€ì¤‘ í‰ê· 
    â”‚           â”‚                   â”‚           â”‚       centroid = sum(freq * mag) / sum(mag)
    â”‚           â”‚                   â”‚           â”‚
    â”‚           â”‚                   â”‚           â””â”€â–¶ kHz ë‹¨ìœ„ ë³€í™˜
    â”‚           â”‚                   â”‚
    â”‚           â”‚                   â””â”€â–¶ return fric_dur_ms, centroid_kHz, confident
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ [AFFRICATE: ã…ˆ, ã…‰, ã…Š]
    â”‚           â”‚       â”‚
    â”‚           â”‚       â”œâ”€â–¶ VOT (íŒŒì—´ìŒ íŠ¹ì§•)
    â”‚           â”‚       â””â”€â–¶ Frication (ë§ˆì°°ìŒ íŠ¹ì§•)
    â”‚           â”‚
    â”‚           â””â”€â–¶ [SONORANT: ã„´, ã„¹, ã…]
    â”‚                   â”‚
    â”‚                   â”œâ”€â–¶ Segment Duration (consonant.py:689)
    â”‚                   â”‚       segment_duration_ms(snd)
    â”‚                   â”‚           duration_ms = snd.get_total_duration() * 1000
    â”‚                   â”‚
    â”‚                   â””â”€â–¶ Nasal Low-Freq Ratio (consonant.py:708)
    â”‚                           lowfreq_ratio(y, sr, cutoff=500)
    â”‚                               â”‚
    â”‚                               â”œâ”€â–¶ ì €ì£¼íŒŒ í•„í„°ë§
    â”‚                               â”‚       lp_sig = lowpass(y, sr, 500)
    â”‚                               â”‚
    â”‚                               â”œâ”€â–¶ ì—ë„ˆì§€ ê³„ì‚°
    â”‚                               â”‚       low_energy = sum(lp_sig^2)
    â”‚                               â”‚       total_energy = sum(y^2)
    â”‚                               â”‚
    â”‚                               â””â”€â–¶ ratio = low_energy / total_energy
    â”‚
    â”œâ”€â–¶ 4. í™”ì F0 ì¶”ì • (consonant.py:881-886)
    â”‚       estimate_speaker_f0_and_sex(wav_path, vot_ms)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ VOT ì´í›„ êµ¬ê°„ì—ì„œ F0 ì¶”ì¶œ
    â”‚           â”‚       offset_s = (vot_ms + extra_offset_ms) / 1000
    â”‚           â”‚       vowel_part = snd.extract_part(offset_s, ...)
    â”‚           â”‚       pitch = vowel_part.to_pitch()
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ìœ ì„±ìŒ í”„ë ˆì„ í•„í„°ë§
    â”‚           â”‚       voiced_frames = [f for f in pitch if 75 < f < 400]
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ì¤‘ì•™ê°’ F0 ê³„ì‚°
    â”‚           â”‚       median_f0 = np.median(voiced_frames)
    â”‚           â”‚
    â”‚           â””â”€â–¶ ì„±ë³„ íŒë³„
    â”‚                   sex = "male" if median_f0 < 160 else "female"
    â”‚
    â”œâ”€â–¶ 5. ì ìˆ˜ ê³„ì‚° (consonant.py:890-894)
    â”‚       score_against_reference(measured, ref_feats, sex)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ê° íŠ¹ì§•ë³„ Z-score ê³„ì‚° (consonant.py:741-756)
    â”‚           â”‚       for feat_name in ref_feats:
    â”‚           â”‚           mean, sd = ref_feats[feat_name][sex]
    â”‚           â”‚           measured_val = measured[feat_name]
    â”‚           â”‚           z = capped_z(measured_val, mean, sd, cap=3.0)
    â”‚           â”‚           z_list.append(abs(z))
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ í‰ê·  Z-score (consonant.py:797)
    â”‚           â”‚       avg_abs_z = sum(z_list) / len(z_list)
    â”‚           â”‚
    â”‚           â”œâ”€â–¶ ì ìˆ˜ ë³€í™˜ (consonant.py:798-802)
    â”‚           â”‚       if avg_abs_z <= 1.5:
    â”‚           â”‚           score = 100
    â”‚           â”‚       else:
    â”‚           â”‚           penalty = (avg_abs_z - 1.5) * 60
    â”‚           â”‚           score = max(0, 100 - penalty)
    â”‚           â”‚
    â”‚           â””â”€â–¶ í”¼ë“œë°± ìƒì„± (consonant.py:758-789)
    â”‚                   íŠ¹ì§•ë³„ ì¡°ì–¸ (VOT, aspiration, frication, nasal...)
    â”‚
    â””â”€â–¶ 6. ê²°ê³¼ ë°˜í™˜ (consonant.py:896-954)
            return {
                "syllable", "sex", "f0", "measured_features",
                "per_feature_report", "overall_score", "advice"
            }
```

### 3.2 ë°œê²¬ëœ ì ì¬ì  ë¬¸ì œì 

#### ğŸ”´ **C1: ì„±ë³„ ì„ê³„ê°’ ë¶ˆì¼ì¹˜**

**ìœ„ì¹˜**:
- `vowel_v2.py:43, 271`: 165Hz
- `consonant.py:544`: 160Hz

```python
# vowel_v2.py
F0_GENDER_THRESHOLD = 165.0
gender_guess = "Male" if f0 < F0_GENDER_THRESHOLD else "Female"

# consonant.py:544
if median_f0 < 160:
    sex_guess = "male"
else:
    sex_guess = "female"
```

**ë¬¸ì œ**:
- ê°™ì€ ì‚¬ìš©ìê°€ ëª¨ìŒê³¼ ììŒì„ ë…¹ìŒí–ˆì„ ë•Œ ì„±ë³„ì´ ë‹¤ë¥´ê²Œ íŒë³„ë  ìˆ˜ ìˆìŒ
- ì˜ˆ: F0 = 162Hz â†’ ëª¨ìŒ: Female, ììŒ: Male

**í•´ê²°ì±…**:
```python
# config.py (ê³µí†µ íŒŒì¼)
F0_GENDER_THRESHOLD = 165.0

# vowel_v2.py
from .config import F0_GENDER_THRESHOLD

# consonant.py
from .config import F0_GENDER_THRESHOLD
```

**ì˜í–¥ë„**: ğŸ”¥ ë†’ìŒ (ì¼ê´€ì„± ë¬¸ì œ)

---

#### ğŸ”´ **C2: None ì ìˆ˜ ë²„ê·¸ (ìˆ˜ì •ë¨)**

**ìœ„ì¹˜**: `consonant.py:791-795` (2025-11-02 ìˆ˜ì •)

**Before**:
```python
if len(z_list) == 0:
    overall_score = None  # âŒ TypeError ìœ ë°œ
```

**After**:
```python
if len(z_list) == 0:
    overall_score = 0.0  # âœ… ì•ˆì „í•œ ê¸°ë³¸ê°’
    advice_list.append("Could not extract enough acoustic features.")
```

**ë°œìƒ ì¡°ê±´**:
- ëª¨ë“  ì¸¡ì •ê°’ì´ Noneì¼ ë•Œ (ì˜ˆ: VOT ê²€ì¶œ ì‹¤íŒ¨, frication ê²€ì¶œ ì‹¤íŒ¨)
- ììŒ íƒ€ì…ê³¼ ì°¸ì¡° ë°ì´í„° ë¶ˆì¼ì¹˜

**ì˜í–¥ë„**: ğŸ”¥ ë†’ìŒ (í¬ë˜ì‹œ ìœ ë°œ) â†’ âœ… í•´ê²°ë¨

---

#### ğŸŸ¡ **C3: Aspirated Mode íŒë³„ ë¡œì§**

**ìœ„ì¹˜**: `consonant.py:329-336, 813-814`

```python
def is_aspirated_like(syllable):
    aspirated_chars = ["ì¹´", "íƒ€", "íŒŒ", "ì°¨"]
    return syllable in aspirated_chars

# extract_features_for_syllable
aspirated_mode = False
if ctype in ["stop", "affricate"] and is_aspirated_like(syllable_label):
    aspirated_mode = True
```

**ë¬¸ì œ**:
- í•˜ë“œì½”ë”©ëœ ë¦¬ìŠ¤íŠ¸
- í™•ì¥ì„± ë‚®ìŒ (ìƒˆ ììŒ ì¶”ê°€ ì‹œ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”)

**ê°œì„ ì•ˆ**:
```python
# reference ë°ì´í„°ì— ì¶”ê°€
reference = {
    "ì¹´": {
        "type": "stop",
        "aspirated": True,  # âœ… ë©”íƒ€ë°ì´í„°ë¡œ ê´€ë¦¬
        "features": {...}
    }
}

# íŒë³„ ë¡œì§
aspirated_mode = info.get("aspirated", False)
```

**ì˜í–¥ë„**: ğŸŸ¡ ì¤‘ê°„ (ìœ ì§€ë³´ìˆ˜ì„±)

---

#### ğŸŸ¡ **C4: Frication ì‹ ë¢°ë„ ê¸°ì¤€ ë¶ˆëª…í™•**

**ìœ„ì¹˜**: `consonant.py:671-683`

```python
confident = False
if fric_dur_ms > 10.0:  # âŒ ë§¤ì§ ë„˜ë²„
    raw_centroid_hz = compute_spectral_centroid(...)
    if raw_centroid_hz is not None and raw_centroid_hz > 100:  # âŒ ë§¤ì§ ë„˜ë²„
        centroid_kHz = raw_centroid_hz / 1000.0
        confident = True
```

**ë¬¸ì œ**:
- 10ms, 100Hz ì„ê³„ê°’ì˜ ê·¼ê±° ë¶ˆëª…í™•
- `confident=False`ì¼ ë•Œ None ë°˜í™˜ â†’ z_listì— ì¶”ê°€ ì•ˆ ë¨ â†’ ì ìˆ˜ ê³„ì‚°ì—ì„œ ì œì™¸

**ì˜í–¥**:
- ã……, ã…†, ã… ë¶„ì„ ì‹œ frication ê²€ì¶œ ì‹¤íŒ¨ ì‹œ 0ì  ê°€ëŠ¥ì„±

**ê¶Œì¥**:
```python
# ìƒìˆ˜í™”
MIN_FRICATION_DURATION_MS = 10.0  # ã…… ìµœì†Œ ì§€ì† ì‹œê°„
MIN_CENTROID_HZ = 100.0           # ìœ ì˜ë¯¸í•œ ìŠ¤í™íŠ¸ëŸ¼ ì¤‘ì‹¬
```

**ì˜í–¥ë„**: ğŸŸ¡ ì¤‘ê°„

---

#### ğŸŸ¢ **C5: Z-score Capping**

**ìœ„ì¹˜**: `consonant.py:726-734`

```python
def capped_z(value, mean, sd, cap=3.0):
    z = raw_z_score(value, mean, sd)
    if z is None:
        return None
    if z > cap:
        return cap  # âœ… 3Ïƒ ì´ìƒì€ 3ìœ¼ë¡œ ì œí•œ
    if z < -cap:
        return -cap
    return z
```

**íŠ¹ì§•**:
- Z-scoreë¥¼ Â±3Ïƒë¡œ ì œí•œ
- ê·¹ë‹¨ê°’ ë°©ì§€ (outlier ì²˜ë¦¬)

**ì¥ì **:
- ì¡ìŒì´ ë§ì€ ìƒ˜í”Œì— ëŒ€í•´ ê³¼ë„í•œ íŒ¨ë„í‹° ë°©ì§€

**ë‹¨ì **:
- ë§¤ìš° ì˜ëª»ëœ ë°œìŒë„ ì¼ì • ìˆ˜ì¤€ ì´ìƒ íŒ¨ë„í‹° ë°›ì§€ ì•ŠìŒ

**ê¶Œì¥**: í˜„ì¬ êµ¬í˜„ì´ í•©ë¦¬ì . ìœ ì§€.

**ì˜í–¥ë„**: ğŸŸ¢ ë‚®ìŒ (ì •ìƒ ì‘ë™)

---

### 3.3 ì„±ëŠ¥ ë¶„ì„

#### VOT ì¸¡ì • ë³µì¡ë„

**ìœ„ì¹˜**: `consonant.py:338-428`

**ì‹œê°„ ë³µì¡ë„**:
- Intensity object ìƒì„±: O(n) (Praat ë‚´ë¶€)
- Pitch object ìƒì„±: O(n)
- í”„ë ˆì„ë³„ ìˆœíšŒ: O(frames) â‰ˆ O(n / hop)
- ì´: O(n)

**ì²˜ë¦¬ ì‹œê°„**: ~100-500ms (Praat ì˜ì¡´)

**ë³‘ëª© ì§€ì **:
- `snd.to_intensity()`: ~50-100ms
- `snd.to_pitch()`: ~100-200ms

**ìµœì í™” ê°€ëŠ¥ì„±**:
- ë‚®ìŒ (Praat ì•Œê³ ë¦¬ì¦˜ ì˜ì¡´)
- ìºì‹± ê°€ëŠ¥ (ê°™ì€ ì˜¤ë””ì˜¤ ì¬ë¶„ì„ ì‹œ)

---

## 4. ë°œê²¬ëœ ë¬¸ì œì  ë° ê¶Œì¥ ì‚¬í•­

### 4.1 ì‹¬ê°ë„ë³„ ë¶„ë¥˜

| ì‹¬ê°ë„ | ì½”ë“œ | ë¬¸ì œ | ì˜í–¥ | ìƒíƒœ |
|--------|------|------|------|------|
| ğŸ”´ ë†’ìŒ | V-P1 | ì„ì‹œ íŒŒì¼ ê³ ì •ëª… (Race Condition) | ë™ì‹œ ìš”ì²­ ì‹œ ì¶©ëŒ | âš ï¸ ë¯¸í•´ê²° |
| ğŸ”´ ë†’ìŒ | C-C1 | ì„±ë³„ ì„ê³„ê°’ ë¶ˆì¼ì¹˜ (165 vs 160) | ì¼ê´€ì„± ë¬¸ì œ | âš ï¸ ë¯¸í•´ê²° |
| ğŸ”´ ë†’ìŒ | C-C2 | None ì ìˆ˜ ë²„ê·¸ | í¬ë˜ì‹œ ìœ ë°œ | âœ… í•´ê²°ë¨ |
| ğŸŸ¡ ì¤‘ê°„ | V-P2 | ì„±ë³„ íŒë³„ ë‹¨ìˆœí™” | ì •í™•ë„ ì €í•˜ | âš ï¸ ë¯¸í•´ê²° |
| ğŸŸ¡ ì¤‘ê°„ | V-P3 | ì ìˆ˜ ê³„ì‚° ë¬¸ì„œ ë¶ˆì¼ì¹˜ | í˜¼ë€ ì´ˆë˜ | âš ï¸ ë¯¸í•´ê²° |
| ğŸŸ¡ ì¤‘ê°„ | C-C3 | Aspirated íŒë³„ í•˜ë“œì½”ë”© | ìœ ì§€ë³´ìˆ˜ì„± | âš ï¸ ë¯¸í•´ê²° |
| ğŸŸ¡ ì¤‘ê°„ | C-C4 | Frication ì‹ ë¢°ë„ ê¸°ì¤€ ë¶ˆëª…í™• | ì ìˆ˜ ë¶ˆì•ˆì • | âš ï¸ ë¯¸í•´ê²° |
| ğŸŸ¢ ë‚®ìŒ | V-P4 | F3 ê°€ì¤‘ì¹˜ ë¶ˆëª…í™• | ë¯¸ë¯¸í•œ ì˜í–¥ | âš ï¸ ë¯¸í•´ê²° |
| ğŸŸ¢ ë‚®ìŒ | V-P5 | ë§¤ì§ ë„˜ë²„ í•˜ë“œì½”ë”© | ê°€ë…ì„± | âš ï¸ ë¯¸í•´ê²° |

### 4.2 ìš°ì„  ìˆœìœ„ë³„ ìˆ˜ì • ê¶Œì¥ ì‚¬í•­

#### ğŸ”¥ **ì¦‰ì‹œ ìˆ˜ì • í•„ìš”**

**1. ì„ì‹œ íŒŒì¼ëª… Race Condition (V-P1)**

```python
# vowel_v2.py:243-249
# Before
tmp_wav = "kospa_temp.wav"

# After
import tempfile
with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
    tmp_wav = tmp.name

if not convert_to_wav(audio_path, tmp_wav):
    ...

try:
    f1, f2, f3, f0, qhint = analyze_vowel_and_pitch(tmp_wav)
finally:
    try:
        os.remove(tmp_wav)
    except OSError:
        pass
```

**2. ì„±ë³„ ì„ê³„ê°’ í†µì¼ (C-C1)**

```python
# analysis/config.py (ìƒˆ íŒŒì¼)
F0_GENDER_THRESHOLD = 165.0  # Hz

# vowel_v2.py
from .config import F0_GENDER_THRESHOLD
gender_guess = "Male" if f0 < F0_GENDER_THRESHOLD else "Female"

# consonant.py
from .config import F0_GENDER_THRESHOLD
sex_guess = "male" if median_f0 < F0_GENDER_THRESHOLD else "female"
```

---

#### ğŸ“‹ **ì°¨í›„ ê°œì„  ì‚¬í•­**

**3. ì ìˆ˜ ê³„ì‚° ë¡œì§ ë¬¸ì„œí™”**

README.md ìˆ˜ì •:
```markdown
# Before
Average z â‰¤ 2.5 scores 100; beyond that, the score decreases linearly (â‰ˆ40 points per Ïƒ).

# After
Average z â‰¤ 1.5 scores 100; beyond that, the score decreases linearly (60 points per Ïƒ).
Score = max(0, 100 - (z_avg - 1.5) * 60)
```

**4. ìƒìˆ˜ ì¶”ì¶œ ë° ì¤‘ì•™ ê´€ë¦¬**

```python
# analysis/config.py
# Vowel Analysis
MIN_SEGMENT_LENGTH = 0.08  # seconds
MIN_RMS_THRESHOLD = 0.01
MIN_SNR_RATIO = 1.5

# Consonant Analysis
MIN_FRICATION_DURATION_MS = 10.0
MIN_CENTROID_HZ = 100.0

# Scoring
PERFECT_SCORE_THRESHOLD = 1.5  # sigma
PENALTY_PER_SIGMA = 60.0  # points
```

---

## 5. ì½”ë“œ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

### 5.1 ì „ì²´ ìš”ì²­ ì²˜ë¦¬ íë¦„

```
[User Browser]
     â”‚
     â”‚ 2ì´ˆ ë…¹ìŒ (MediaRecorder API)
     â”‚ â†’ Blob (audio/webm, Opus codec)
     â–¼
[POST /api/analyze-sound]
     â”‚ multipart/form-data
     â”‚ - audio: File
     â”‚ - userid: int
     â”‚ - sound: string ("ã…" or "ã„±")
     â–¼
[main.py:468] analyze_sound()
     â”‚
     â”œâ”€ userid ê²€ì¦ (DB query)
     â”‚
     â”œâ”€ analyse_uploaded_audio(audio, sound)  # main.py:231
     â”‚     â”‚
     â”‚     â”œâ”€ resolve_sound_symbol(sound)  # main.py:83
     â”‚     â”‚     â”‚
     â”‚     â”‚     â”œâ”€ if sound in VOWEL_SYMBOL_TO_KEY â†’ "vowel"
     â”‚     â”‚     â””â”€ if sound in CONSONANT_SYMBOL_TO_SYLLABLE â†’ "consonant"
     â”‚     â”‚
     â”‚     â”œâ”€ save_upload_to_temp(audio)  # main.py:109
     â”‚     â”‚     â”‚
     â”‚     â”‚     â””â”€ NamedTemporaryFile(suffix=".webm")  # âœ… ì•ˆì „
     â”‚     â”‚
     â”‚     â”œâ”€ [IF VOWEL]
     â”‚     â”‚     run_vowel_analysis(temp_path, symbol)  # main.py:124
     â”‚     â”‚         â”‚
     â”‚     â”‚         â”œâ”€ analyze_single_audio()  # vowel_v2.py:225
     â”‚     â”‚         â”‚     â”‚
     â”‚     â”‚         â”‚     â”œâ”€ convert_to_wav()  # âš ï¸ Race Condition!
     â”‚     â”‚         â”‚     â”œâ”€ analyze_vowel_and_pitch()
     â”‚     â”‚         â”‚     â”œâ”€ compute_score()
     â”‚     â”‚         â”‚     â””â”€ get_feedback()
     â”‚     â”‚         â”‚
     â”‚     â”‚         â””â”€ plot_single_vowel_space()  # ì„ íƒì 
     â”‚     â”‚
     â”‚     â””â”€ [IF CONSONANT]
     â”‚           run_consonant_analysis(temp_path, symbol)  # main.py:169
     â”‚               â”‚
     â”‚               â”œâ”€ convert_to_wav()  # vowel_v2ì—ì„œ import
     â”‚               â”œâ”€ consonant_analysis.load_sound()
     â”‚               â”œâ”€ extract_features_for_syllable()
     â”‚               â”œâ”€ estimate_speaker_f0_and_sex()
     â”‚               â””â”€ score_against_reference()
     â”‚
     â”œâ”€ normalise_score(score)  # main.py:244
     â”‚
     â”œâ”€ [DB UPDATE] progress í…Œì´ë¸” ì—…ë°ì´íŠ¸
     â”‚     UPDATE progress SET progress = GREATEST(progress, %s)
     â”‚     WHERE userid = %s AND sound = %s
     â”‚
     â””â”€ return JSON response
           {
               "score": 85,
               "feedback": "...",
               "details": {...}
           }
```

### 5.2 ì˜ì¡´ì„± ê·¸ë˜í”„

```
main.py
    â”‚
    â”œâ”€ imports
    â”‚   â”œâ”€ analysis.vowel_v2
    â”‚   â”‚   â”œâ”€ analyze_single_audio âœ…
    â”‚   â”‚   â”œâ”€ convert_to_wav âœ…
    â”‚   â”‚   â”œâ”€ STANDARD_MALE_FORMANTS âœ…
    â”‚   â”‚   â”œâ”€ STANDARD_FEMALE_FORMANTS âœ…
    â”‚   â”‚   â””â”€ plot_single_vowel_space âœ…
    â”‚   â”‚
    â”‚   â””â”€ analysis.consonant (as consonant_analysis)
    â”‚       â”œâ”€ reference âœ…
    â”‚       â”œâ”€ load_sound âœ…
    â”‚       â”œâ”€ extract_features_for_syllable âœ…
    â”‚       â”œâ”€ estimate_speaker_f0_and_sex âœ…
    â”‚       â””â”€ score_against_reference âœ…
    â”‚
    â””â”€ internal dependencies
        â”œâ”€ psycopg2 (DB)
        â”œâ”€ fastapi
        â”œâ”€ jinja2
        â””â”€ tempfile

vowel_v2.py
    â”‚
    â”œâ”€ external libs
    â”‚   â”œâ”€ numpy âœ…
    â”‚   â”œâ”€ parselmouth âœ…
    â”‚   â”œâ”€ matplotlib âœ…
    â”‚   â””â”€ subprocess (ffmpeg) âœ…
    â”‚
    â””â”€ internal calls
        analyze_single_audio()
            â””â”€ convert_to_wav()  # âš ï¸ Race Condition
                â””â”€ analyze_vowel_and_pitch()
                    â””â”€ _stable_window()
                        â””â”€ compute_score()
                            â””â”€ get_feedback()
                                â””â”€ plot_single_vowel_space()

consonant.py
    â”‚
    â”œâ”€ external libs
    â”‚   â”œâ”€ numpy âœ…
    â”‚   â”œâ”€ scipy.signal âœ…
    â”‚   â”œâ”€ parselmouth âœ…
    â”‚   â””â”€ (vowel_v2.convert_to_wav) âœ… [ê°„ì ‘ ì˜ì¡´]
    â”‚
    â””â”€ internal calls
        analyze_one_file()  # main ë¶„ì„ í•¨ìˆ˜ (main.pyì—ì„œëŠ” ì§ì ‘ í˜¸ì¶œ ì•ˆ í•¨)
            â””â”€ load_sound()
                â””â”€ extract_features_for_syllable()
                    â”œâ”€ [STOP] estimate_vot_ms()
                    â”‚           â””â”€ detect_burst_time()
                    â”‚           â””â”€ aspiration_ratio_after_burst()
                    â”‚                   â””â”€ bandpass()
                    â”‚
                    â”œâ”€ [FRICATIVE] frication_stats()
                    â”‚               â””â”€ compute_spectral_centroid()
                    â”‚
                    â””â”€ [SONORANT] segment_duration_ms()
                                  lowfreq_ratio()
                                      â””â”€ lowpass()

                    â””â”€ estimate_speaker_f0_and_sex()
                        â””â”€ score_against_reference()
                            â””â”€ capped_z()
                                â””â”€ raw_z_score()
```

### 5.3 ìƒí˜¸ ì˜ì¡´ì„± ìš”ì•½

| íŒŒì¼ | ì˜ì¡´ ëŒ€ìƒ | ì œê³µ ê¸°ëŠ¥ |
|------|-----------|-----------|
| **main.py** | vowel_v2, consonant, psycopg2, fastapi | API ì—”ë“œí¬ì¸íŠ¸, ë¼ìš°íŒ… |
| **vowel_v2.py** | parselmouth, numpy, matplotlib, subprocess | ëª¨ìŒ ë¶„ì„, FFmpeg ë³€í™˜ |
| **consonant.py** | parselmouth, numpy, scipy, (vowel_v2) | ììŒ ë¶„ì„ |

**ì£¼ì˜**: `consonant.py`ëŠ” `vowel_v2.convert_to_wav`ë¥¼ ê°„ì ‘ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, main.pyì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ë¯€ë¡œ ìˆœí™˜ ì˜ì¡´ì„± ì—†ìŒ.

---

## 6. ê²°ë¡  ë° ì¢…í•© ê¶Œì¥ ì‚¬í•­

### 6.1 ì—”ì§„ í’ˆì§ˆ í‰ê°€

| í•­ëª© | í‰ê°€ | ìƒì„¸ |
|------|------|------|
| **ì•Œê³ ë¦¬ì¦˜ ì •í™•ì„±** | â­â­â­â­â˜† | ìŒì„±í•™ ì´ë¡  ê¸°ë°˜, í•©ë¦¬ì ì¸ êµ¬í˜„ |
| **ì½”ë“œ ì•ˆì •ì„±** | â­â­â­â˜†â˜† | Race Condition, None ë²„ê·¸ ì¡´ì¬ |
| **ì„±ëŠ¥** | â­â­â­â­â˜† | 1-3ì´ˆ ì²˜ë¦¬ ì‹œê°„, ì‹¤ì‹œê°„ í”¼ë“œë°± ê°€ëŠ¥ |
| **í™•ì¥ì„±** | â­â­â­â˜†â˜† | í•˜ë“œì½”ë”© ë§ìŒ, ìƒˆ ìŒì†Œ ì¶”ê°€ ì–´ë ¤ì›€ |
| **ìœ ì§€ë³´ìˆ˜ì„±** | â­â­â­â˜†â˜† | ë¬¸ì„œí™” ë¶€ì¡±, ë§¤ì§ ë„˜ë²„ ë§ìŒ |

### 6.2 ìš°ì„ ìˆœìœ„ë³„ ê°œì„  ë¡œë“œë§µ

#### Phase 1: ê¸´ê¸‰ ìˆ˜ì • (ë°°í¬ ì „ í•„ìˆ˜)
1. âœ… None ì ìˆ˜ ë²„ê·¸ ìˆ˜ì • (ì™„ë£Œ)
2. âš ï¸ ì„ì‹œ íŒŒì¼ Race Condition ìˆ˜ì •
3. âš ï¸ ì„±ë³„ ì„ê³„ê°’ í†µì¼

#### Phase 2: í’ˆì§ˆ ê°œì„  (ë°°í¬ í›„ 1ê°œì›” ë‚´)
4. ìƒìˆ˜ ì¤‘ì•™í™” (config.py)
5. ë¬¸ì„œ-ì½”ë“œ ì¼ì¹˜ì„± í™•ë³´
6. ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™”

#### Phase 3: ì¥ê¸° ê°œì„  (2ê°œì›”~)
7. ì„±ë³„ íŒë³„ ì•Œê³ ë¦¬ì¦˜ ê°œì„ 
8. ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ê¸°ëŠ¥ êµ¬í˜„
9. ì°¸ì¡° ë°ì´í„° í™•ì¥ (ë³µëª¨ìŒ, ê²¹ë°›ì¹¨)

---

**ë¶„ì„ì**: Claude Code
**ë¶„ì„ ì™„ë£Œì¼**: 2025-11-02
**ë‹¤ìŒ ë¦¬ë·° ì˜ˆì •ì¼**: ë°°í¬ í›„ 1ê°œì›”
