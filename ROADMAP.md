# KoSPA ê°œë°œ ë¡œë“œë§µ

## í˜„ìž¬ ìƒíƒœ: Stage 2 ì™„ë£Œ âœ…

### âœ… Stage 1: ê¸°ë³¸ ìŒì†Œ ë¶„ì„ (ì™„ë£Œ)
- [x] ëª¨ìŒ 6ê°œ ë¶„ì„ (ã…, ã…“, ã…—, ã…œ, ã…¡, ã…£)
- [x] ìžìŒ 18ê°œ ë¶„ì„ (í‰ìŒ/ê²½ìŒ/ê²©ìŒ)
- [x] í¬ë¨¼íŠ¸ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
- [x] VOT/Aspiration/Frication ì¸¡ì •
- [x] ì‹¤ì‹œê°„ í”¼ë“œë°± ìƒì„±

### âœ… Stage 2: ì‹œìŠ¤í…œ ì•ˆì •í™” (ì™„ë£Œ)
- [x] Race Condition ë²„ê·¸ ìˆ˜ì •
- [x] ì„±ë³„ ìž„ê³„ê°’ í†µì¼
- [x] ëª¨ë°”ì¼ ì§€ì› (ngrok)
- [x] ë°°í¬ ì¤€ë¹„ (Render.com)
- [x] ë¬¸ì„œí™”

---

## ðŸš§ Stage 3: ë°ì´í„° ìˆ˜ì§‘ & í†µê³„ ê°œì„ 

### ëª©í‘œ
ì‹¤ì œ ì‚¬ìš©ìž ë°ì´í„°ë¡œ ì°¸ì¡°ê°’(mean/std) ì—…ë°ì´íŠ¸í•˜ì—¬ ì •í™•ë„ í–¥ìƒ

### 3.1 ë°ì´í„° ìˆ˜ì§‘ ì‹œìŠ¤í…œ

#### í•„ìš”í•œ ê¸°ëŠ¥
```python
# 1. ì‚¬ìš©ìž ë…¹ìŒ ì €ìž¥
POST /api/submit-recording
- userid, sound, audio_file
- ì„œë²„ì— WAV íŒŒì¼ ì €ìž¥ (ë˜ëŠ” S3)
- metadata ì €ìž¥ (F0, F1, F2, F3, gender, score)

# 2. í†µê³„ ê³„ì‚°
- ìŒì†Œë³„ N >= 30ê°œ ìƒ˜í”Œ ìˆ˜ì§‘
- mean, std ìžë™ ê³„ì‚°
- ì´ìƒì¹˜(outlier) ì œê±° (Â±3Ïƒ ì´ˆê³¼)

# 3. ì°¸ì¡°ê°’ ì—…ë°ì´íŠ¸
- analysis/config.pyì— ìƒˆ í†µê³„ ë°˜ì˜
- A/B í…ŒìŠ¤íŠ¸ë¡œ ê°œì„  íš¨ê³¼ ê²€ì¦
```

#### ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì¶”ê°€
```sql
CREATE TABLE recordings (
    id SERIAL PRIMARY KEY,
    userid INTEGER REFERENCES users(id),
    sound VARCHAR(10),           -- "ã…", "ã„±" ë“±
    audio_path TEXT,             -- S3 URL ë˜ëŠ” ë¡œì»¬ ê²½ë¡œ
    f0 FLOAT,
    f1 FLOAT,
    f2 FLOAT,
    f3 FLOAT,
    gender VARCHAR(10),
    score INTEGER,
    created_at TIMESTAMP DEFAULT NOW(),
    is_outlier BOOLEAN DEFAULT FALSE
);

CREATE INDEX idx_recordings_sound ON recordings(sound);
CREATE INDEX idx_recordings_gender ON recordings(gender);
```

#### í†µê³„ ì—…ë°ì´íŠ¸ ìŠ¤í¬ë¦½íŠ¸
```python
# scripts/update_statistics.py

from sqlalchemy import create_engine
import pandas as pd
import numpy as np

def update_formant_statistics(sound, gender):
    """
    íŠ¹ì • ìŒì†Œì˜ í†µê³„ê°’ ì—…ë°ì´íŠ¸
    """
    # 1. ë°ì´í„° ë¡œë“œ (N >= 30)
    query = f"""
        SELECT f1, f2, f3
        FROM recordings
        WHERE sound = '{sound}'
          AND gender = '{gender}'
          AND is_outlier = FALSE
    """
    df = pd.read_sql(query, engine)

    if len(df) < 30:
        print(f"âŒ {sound} ({gender}): ìƒ˜í”Œ ë¶€ì¡± ({len(df)}/30)")
        return None

    # 2. ì´ìƒì¹˜ ì œê±° (Â±3Ïƒ)
    for col in ['f1', 'f2', 'f3']:
        mean = df[col].mean()
        std = df[col].std()
        df = df[np.abs(df[col] - mean) <= 3 * std]

    # 3. í†µê³„ ê³„ì‚°
    stats = {
        'f1': df['f1'].mean(),
        'f1_sd': df['f1'].std(),
        'f2': df['f2'].mean(),
        'f2_sd': df['f2'].std(),
        'f3': df['f3'].mean(),
        'f3_sd': df['f3'].std(),
    }

    print(f"âœ… {sound} ({gender}): N={len(df)}")
    print(f"   F1: {stats['f1']:.0f} Â± {stats['f1_sd']:.0f} Hz")
    print(f"   F2: {stats['f2']:.0f} Â± {stats['f2_sd']:.0f} Hz")

    return stats

# 4. config íŒŒì¼ ìžë™ ìƒì„±
def generate_config_file(all_stats):
    """
    analysis/formant_data.py ìžë™ ìƒì„±
    """
    with open('analysis/formant_data.py', 'w') as f:
        f.write("# Auto-generated from user data\n")
        f.write("# Last updated: {datetime.now()}\n\n")
        f.write("UPDATED_MALE_FORMANTS = {\n")
        for sound, stats in all_stats['male'].items():
            f.write(f"    '{sound}': {stats},\n")
        f.write("}\n\n")
        # ... Femaleë„ ë™ì¼
```

#### API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
```python
# main.py

@app.post("/api/submit-recording")
async def submit_recording(
    userid: int,
    sound: str,
    audio: UploadFile
):
    """
    ì‚¬ìš©ìž ë…¹ìŒì„ ì„œë²„ì— ì €ìž¥í•˜ê³  í†µê³„ì— ë°˜ì˜
    """
    # 1. ë¶„ì„
    result = await analyse_uploaded_audio(audio, sound)

    # 2. ì €ìž¥
    audio_path = save_to_s3(audio)  # ë˜ëŠ” ë¡œì»¬

    with connect(DB_URL) as conn:
        cursor = conn.cursor()
        cursor.execute("""
            INSERT INTO recordings
            (userid, sound, audio_path, f0, f1, f2, f3, gender, score)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            userid, sound, audio_path,
            result['f0'], result['f1'], result['f2'], result['f3'],
            result['gender'], result['score']
        ))
        conn.commit()

    return {"ok": True, "message": "Recording saved for statistics"}
```

### 3.2 êµ¬í˜„ ìš°ì„ ìˆœìœ„

**Phase 1: ë°ì´í„° ìˆ˜ì§‘ (1~2ì£¼)**
- [ ] recordings í…Œì´ë¸” ìƒì„±
- [ ] /api/submit-recording ì—”ë“œí¬ì¸íŠ¸
- [ ] í”„ë¡ íŠ¸ì—”ë“œ: "í†µê³„ ì œê³µ ë™ì˜" ì²´í¬ë°•ìŠ¤
- [ ] ìµœì†Œ 30ê°œ/ìŒì†Œ ìˆ˜ì§‘

**Phase 2: í†µê³„ ë¶„ì„ (1ì£¼)**
- [ ] ì´ìƒì¹˜ ì œê±° ë¡œì§
- [ ] update_statistics.py ìŠ¤í¬ë¦½íŠ¸
- [ ] A/B í…ŒìŠ¤íŠ¸ ì¤€ë¹„

**Phase 3: ë°°í¬ (1ì£¼)**
- [ ] ìƒˆ í†µê³„ê°’ ì ìš©
- [ ] ì ìˆ˜ ê°œì„  íš¨ê³¼ ì¸¡ì •
- [ ] ì‚¬ìš©ìž í”¼ë“œë°± ìˆ˜ì§‘

---

## ðŸ¤– Stage 4: ë‹¨ì–´ ìˆ˜ì¤€ ë¶„ì„ (LLM í™œìš©)

### ëª©í‘œ
ë‹¨ì–´/ë¬¸ìž¥ ë°œìŒì„ ë¶„ì„í•˜ê³  ìžì—°ìŠ¤ëŸ¬ìš´ í”¼ë“œë°± ì œê³µ

### 4.1 ì™œ LLMì´ í•„ìš”í•œê°€?

#### ê¸°ì¡´ ìŒì†Œ ë¶„ì„ì˜ í•œê³„
```
ì‚¬ìš©ìž: "ì•ˆë…•í•˜ì„¸ìš”" ë°œìŒ
â†’ í˜„ìž¬: ê° ìŒì†Œë³„ ì ìˆ˜ë§Œ ì œê³µ
   ã…‡: 85ì , ã…: 90ì , ã„´: 80ì , ...

â†’ ë¬¸ì œì :
   - ì—°ìŒ ë²•ì¹™ (ì•ˆë…• â†’ [ì•ˆë…•])
   - ì–µì–‘/ê°•ì„¸ ë¬´ì‹œ
   - ìžì—°ìŠ¤ëŸ¬ì›€ í‰ê°€ ë¶ˆê°€
```

#### LLMìœ¼ë¡œ í•´ê²° ê°€ëŠ¥í•œ ê²ƒ
1. **ìŒìš´ ë³€í™” ì¸ì‹**
   - "êµ­ë¬¼" â†’ [ê¶ë¬¼] (ë¹„ìŒí™”)
   - "ë†“ê³ " â†’ [ë…¸ì½”] (ê²©ìŒí™”)
   - LLMì´ "ì˜ˆìƒ ë°œìŒ"ê³¼ "ì‹¤ì œ ë°œìŒ" ë¹„êµ

2. **ìžì—°ìŠ¤ëŸ¬ì›€ í‰ê°€**
   ```python
   # Whisperë¡œ STT
   transcription = whisper.transcribe("ì•ˆë…•í•˜ì„¸ìš”.wav")
   # â†’ "ì•ˆë…•í•˜ì„¸ìš”"

   # GPTë¡œ í‰ê°€
   prompt = f"""
   Target: ì•ˆë…•í•˜ì„¸ìš”
   Actual: {transcription}

   1. Pronunciation accuracy (0-100)
   2. Natural flow (0-100)
   3. Specific feedback in Korean
   """

   feedback = openai.chat.completions.create(
       model="gpt-4",
       messages=[{"role": "user", "content": prompt}]
   )
   ```

3. **ë§¥ë½ ê¸°ë°˜ í”¼ë“œë°±**
   - "ë°°ìš°ê³  ìžˆì–´ìš”" â†’ ê²©ì‹ì²´/ë¹„ê²©ì‹ì²´ êµ¬ë¶„
   - ìƒí™©ì— ë§žëŠ” ì–µì–‘ ì œì•ˆ

### 4.2 ì•„í‚¤í…ì²˜ ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User: "ì•ˆë…•í•˜ì„¸ìš”" ë…¹ìŒ (3~5ì´ˆ)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: ìŒì†Œ ë¶„ì„ (ê¸°ì¡´ ì—”ì§„)          â”‚
â”‚  - ê° ìŒì†Œë³„ ì ìˆ˜                        â”‚
â”‚  - í¬ë¨¼íŠ¸/VOT ì¸¡ì •                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: STT (Whisper API)             â”‚
â”‚  - ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜                   â”‚
â”‚  - ë°œìŒ ì˜¤ë¥˜ ê°ì§€                        â”‚
â”‚    Input: audio.wav                     â”‚
â”‚    Output: "ì•ˆë…•í•˜ì„¸ìš”" (confidence)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: LLM ë¶„ì„ (GPT-4)              â”‚
â”‚  - ìŒìš´ ê·œì¹™ ì ìš© ì—¬ë¶€ í™•ì¸              â”‚
â”‚  - ì–µì–‘/ê°•ì„¸ í‰ê°€                        â”‚
â”‚  - ìžì—°ìŠ¤ëŸ¬ìš´ í”¼ë“œë°± ìƒì„±                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output: ì¢…í•© í”¼ë“œë°±                     â”‚
â”‚  - ìŒì†Œ ì ìˆ˜: 85/100                    â”‚
â”‚  - ë‹¨ì–´ ì ìˆ˜: 90/100                    â”‚
â”‚  - í”¼ë“œë°±: "ì—°ìŒì´ ìžì—°ìŠ¤ëŸ½ìŠµë‹ˆë‹¤.       â”‚
â”‚    ë‹¤ë§Œ 'í•˜ì„¸ìš”'ì˜ ê°•ì„¸ë¥¼ ì¡°ê¸ˆ ë”..."   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 LLM í†µí•© ë°©ë²•

#### ì˜µì…˜ A: OpenAI API (ì¶”ì²œ)
```python
import openai

async def analyze_word_pronunciation(
    audio_path: str,
    target_text: str,
    phoneme_scores: dict
):
    # 1. Whisper STT
    with open(audio_path, "rb") as audio:
        transcription = openai.Audio.transcribe(
            model="whisper-1",
            file=audio,
            language="ko"
        )

    # 2. GPT-4 í‰ê°€
    prompt = f"""
    You are a Korean pronunciation expert.

    Target phrase: {target_text}
    User said: {transcription.text}
    Phoneme scores: {phoneme_scores}

    Analyze:
    1. Phonological rules applied correctly? (ì—°ìŒ, ë¹„ìŒí™” ë“±)
    2. Natural intonation? (ì–µì–‘)
    3. Overall fluency score (0-100)
    4. Specific feedback in Korean (2-3 sentences)

    Output JSON format:
    {{
        "word_score": 85,
        "intonation_score": 80,
        "fluency_score": 90,
        "feedback": "...",
        "phonological_rules": ["ì—°ìŒ: ì •í™•", "ë¹„ìŒí™”: ë¶€ì¡±"]
    }}
    """

    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)
```

**ìž¥ì **:
- âœ… í•œêµ­ì–´ íŠ¹í™” (Whisper í•œêµ­ì–´ ì„±ëŠ¥ ìš°ìˆ˜)
- âœ… êµ¬í˜„ ê°„ë‹¨
- âœ… í™•ìž¥ì„± ì¢‹ìŒ

**ë‹¨ì **:
- âŒ API ë¹„ìš© (Whisper $0.006/ë¶„, GPT-4 $0.03/1K tokens)
- âŒ ë ˆì´í„´ì‹œ 2~5ì´ˆ

#### ì˜µì…˜ B: ë¡œì»¬ LLM (Llama 3.1 + Whisper)
```python
from transformers import pipeline

# Whisper ë¡œì»¬
whisper = pipeline("automatic-speech-recognition",
                   model="openai/whisper-large-v3")

# Llama 3.1 ë¡œì»¬
llm = pipeline("text-generation",
               model="meta-llama/Llama-3.1-8B-Instruct")

transcription = whisper(audio_path)
feedback = llm(prompt)
```

**ìž¥ì **:
- âœ… ë¬´ë£Œ
- âœ… í”„ë¼ì´ë²„ì‹œ ë³´í˜¸
- âœ… ì˜¤í”„ë¼ì¸ ê°€ëŠ¥

**ë‹¨ì **:
- âŒ GPU í•„ìš” (ìµœì†Œ 16GB VRAM)
- âŒ í•œêµ­ì–´ ì„±ëŠ¥ OpenAIë³´ë‹¤ ë‚®ìŒ
- âŒ ê´€ë¦¬ ë³µìž¡

#### ì˜µì…˜ C: í•˜ì´ë¸Œë¦¬ë“œ
```python
# ìŒì†Œ ë¶„ì„: ë¡œì»¬ (ë¬´ë£Œ, ë¹ ë¦„)
phoneme_result = vowel_v2.analyze_single_audio(...)

# ë‹¨ì–´ ë¶„ì„: OpenAI API (ì •í™•, ìœ ë£Œ)
if user.premium or demo_mode:
    word_result = analyze_with_openai(...)
else:
    word_result = None  # ê¸°ë³¸ ì‚¬ìš©ìžëŠ” ìŒì†Œë§Œ
```

### 4.4 ë¹„ìš© ì¶”ì •

#### OpenAI API ë¹„ìš© (ë‹¨ì–´ ë¶„ì„ 1íšŒ)
```
- Whisper: 5ì´ˆ ì˜¤ë””ì˜¤ â†’ $0.0005
- GPT-4: 500 tokens â†’ $0.015
- ì´: ~$0.0155/ìš”ì²­

ì›” 1,000ëª… Ã— 10íšŒ = 10,000 ìš”ì²­
â†’ $155/ì›”
```

#### ë¬´ë£Œ Tierë¡œ ì œí•œ
```python
# ì‚¬ìš©ìžë³„ ì œí•œ
if user.word_analysis_count < 10:  # ì›” 10íšŒ ë¬´ë£Œ
    result = analyze_with_openai(...)
    user.word_analysis_count += 1
else:
    return {"error": "ì›” ë¬´ë£Œ í• ë‹¹ëŸ‰ ì´ˆê³¼. í”„ë¦¬ë¯¸ì—„ ê°€ìž… í•„ìš”"}
```

### 4.5 êµ¬í˜„ ë¡œë“œë§µ

**Phase 1: POC (2ì£¼)**
- [ ] OpenAI API ì—°ë™
- [ ] 5ê°œ ìƒ˜í”Œ ë‹¨ì–´ë¡œ í…ŒìŠ¤íŠ¸
  - "ì•ˆë…•í•˜ì„¸ìš”"
  - "ê°ì‚¬í•©ë‹ˆë‹¤"
  - "ì£„ì†¡í•©ë‹ˆë‹¤"
  - "ë§›ìžˆì–´ìš”"
  - "ì¢‹ì•„ìš”"
- [ ] ì •í™•ë„ ê²€ì¦

**Phase 2: í”„ë¡œí† íƒ€ìž… (2ì£¼)**
- [ ] í”„ë¡ íŠ¸ì—”ë“œ UI (ë‹¨ì–´ ì„ íƒ íŽ˜ì´ì§€)
- [ ] ìŒì†Œ + ë‹¨ì–´ ê²°ê³¼ í†µí•© í‘œì‹œ
- [ ] ë¬´ë£Œ/í”„ë¦¬ë¯¸ì—„ Tier êµ¬ë¶„

**Phase 3: í”„ë¡œë•ì…˜ (1ì£¼)**
- [ ] ë¹„ìš© ëª¨ë‹ˆí„°ë§
- [ ] ì—ëŸ¬ í•¸ë“¤ë§
- [ ] ì‚¬ìš©ìž í”¼ë“œë°± ìˆ˜ì§‘

---

## ðŸ“Š ì „ì²´ íƒ€ìž„ë¼ì¸

```
í˜„ìž¬ (2025-11)
    |
    â”œâ”€ Stage 2 ì™„ë£Œ âœ…
    |   - ë°ëª¨ ì„±ê³µ
    |   - ëª¨ë°”ì¼ ì§€ì›
    |
    â”œâ”€ Stage 3: ë°ì´í„° ìˆ˜ì§‘ (1ê°œì›”)
    |   Week 1-2: ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬ì¶•
    |   Week 3-4: 30ê°œ/ìŒì†Œ ìˆ˜ì§‘
    |
    â”œâ”€ Stage 3.5: í†µê³„ ì—…ë°ì´íŠ¸ (1ì£¼)
    |   - ì´ìƒì¹˜ ì œê±°
    |   - ìƒˆ í†µê³„ê°’ ë°°í¬
    |
    â””â”€ Stage 4: LLM í†µí•© (1.5ê°œì›”)
        Week 1-2: POC
        Week 3-4: í”„ë¡œí† íƒ€ìž…
        Week 5-6: í”„ë¡œë•ì…˜
```

---

## ðŸŽ¯ ì¦‰ì‹œ í•´ì•¼ í•  ê²ƒ

### ìš°ì„ ìˆœìœ„ 1: ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘
```sql
-- 1. DB ìŠ¤í‚¤ë§ˆ ì¶”ê°€
CREATE TABLE recordings (...);

-- 2. API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
POST /api/submit-recording

-- 3. í”„ë¡ íŠ¸ì—”ë“œ: ë™ì˜ ì²´í¬ë°•ìŠ¤
"ë¶„ì„ ë°ì´í„°ë¥¼ ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤"
```

### ìš°ì„ ìˆœìœ„ 2: LLM POC
```python
# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
import openai

openai.api_key = "sk-..."

response = openai.Audio.transcribe(
    model="whisper-1",
    file=open("sample/vowel_man/ì•„.m4a", "rb")
)

print(response.text)  # "ì•„"
```

---

## ðŸ’¡ ì¶”ì²œ ì „ëžµ

### ë‹¨ê¸° (ì´ë²ˆ í•™ê¸° ë‚´)
1. **ë°ì´í„° ìˆ˜ì§‘ ì‹œìž‘** â†’ í†µê³„ ê°œì„ 
2. **LLM POC** â†’ 5ê°œ ë‹¨ì–´ë¡œ ê°€ëŠ¥ì„± ê²€ì¦

### ì¤‘ê¸° (ë‹¤ìŒ í•™ê¸°)
1. ë‹¨ì–´ ë¶„ì„ ì •ì‹ ì¶œì‹œ
2. í”„ë¦¬ë¯¸ì—„ ëª¨ë¸ ë„ìž… ($5/ì›”)

### ìž¥ê¸° (ë…¼ë¬¸/ì·¨ì—…)
1. ë…¼ë¬¸: "LLM-based Korean Pronunciation Feedback System"
2. í¬íŠ¸í´ë¦¬ì˜¤: ì‹¤ì‚¬ìš©ìž 1,000ëª…+

---

**ì§ˆë¬¸**:
1. Stage 3 ë°ì´í„° ìˆ˜ì§‘ë¶€í„° ì‹œìž‘í• ê¹Œìš”?
2. LLM POCë¥¼ ë¨¼ì € í•´ë³¼ê¹Œìš”?
3. ë‘˜ ë‹¤ ë³‘í–‰?

ì–´ë–¤ ë°©í–¥ìœ¼ë¡œ ì§„í–‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?
